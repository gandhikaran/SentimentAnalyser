{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Sentiment:#Created an enum...i.e just assigning values\n",
    "    Negative = 'NEGATIVE'\n",
    "    Neutral = 'NEUTRAL'\n",
    "    Positive = 'POSITIVE'\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.Negative\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.Neutral\n",
    "        else:\n",
    "            return Sentiment.Positive\n",
    "        \n",
    "class ReviewContainer:#A function( evenly_distribute ) can do this job without the class( ReviewContainer ).The class implementation makes the codes neater\n",
    "    def __init__(self,reviews):\n",
    "        self.reviews = reviews\n",
    "    \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x : x.sentiment == Sentiment.Negative, self.reviews))\n",
    "        positive = list(filter(lambda x : x.sentiment == Sentiment.Positive, self.reviews))\n",
    "        #neutral = list(filter(lambda x : x.sentiment == Sentiment.Neutral, self.reviews))\n",
    "        positive_shrunk = positive[:len(negative)]\n",
    "        self.reviews = negative + positive_shrunk \n",
    "        random.shuffle(self.reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name='./ml_data/Sentimental/Books_small_10000.json'\n",
    "\n",
    "reviews=[]\n",
    "\n",
    "with open(file_name,encoding='utf-8-sig') as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'],review['overall']))#Creates list of objects instead of just appending data to list. Gets easy for data handling\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, test = train_test_split(reviews,test_size=0.33,random_state=42)#random_state: used as seed(first input for random number generator) for shuffling data into train and split.\n",
    "\n",
    "train_cont= ReviewContainer(training)\n",
    "test_cont= ReviewContainer(test)\n",
    "train_cont.evenly_distribute()\n",
    "test_cont.evenly_distribute()\n",
    "print(len(train_cont.reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=[x.text for x in train_cont.reviews]\n",
    "train_y=[x.sentiment for x in train_cont.reviews]\n",
    "\n",
    "test_x=[x.text for x in test_cont.reviews]\n",
    "test_y=[x.sentiment for x in test_cont.reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bags of Words Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me preface this review by saying I have read and enjoyed every book Grisham has written. Generally he is quite entertaining and the reader usually doesn't know what's coming at the end. Sadly, this book isn't up to the same quality of his other legal fiction.He starts with the suicide of a wealthy man who has just  written (as in ink on paper) a new will. The term holographic will should not be strange to any Grisham fan, as his earlier book, The Testament, begins the same way.I will try not to give away anything we learn at the end, although I will say i figured it out very early in this slow reading book. We do learn early on that there is an earlier will, prepared by some hotshot lawyers at a big out of town law firm. It leaves his assets to his kids and grandkids and uses the full extent of legal mumbo jumbo, tax planning and other legerdemain  to minimize the estate taxes due upon one's death. All well and good--the guy was smart, made a lot of money, and didn't want the taxman to get his mitts into his pile of cash. I liked the guy.So, if you have slogged through this book to the end, I'll ask you some simple questions:1. If you wanted to take care of someone, would you wait YEARS until you are literally dead before you did ANYTHING to help that person? There are a lot of ways to transfer assets/cash, with minimal tax consequences.2. If you wanted to leave someone your estate after death, why would you create a freakin' prior will and then hire Jake Brigance to fight the other beneficiaries because you never revoked that earlier will while alive? It would be INSANE to do this. If you hated your family, and Seth makes it clear he did, why ever sit down and create such a document? Even if you changed your mind after creating the first will, send the big shot law firm a notarized (or whatever) letter that simply says I revoke my will of such and such a date, signed Seth Hubbard. Have a nice day! Or go to their office in the flesh, whatever--it is your money and the lawyers are simply carrying out your wishes. You have the right to change your mind. Ask for the original out of their vault (yes there is a will vault) and tear it up with witnesses present. The ultimate revocation!3. Then, have that same hotshot law firm, using the same tax minimizing tricks, create a new will that leaves the money to your beneficiary of choice, again minimizing what the taxman collects, using generation skipping trusts, etc.. This is what a smart businessman like Seth Hubbard would have done.4. Even if you developed memory problems and had forgotten the address of the bigshot law firm, if you knew you were going to kill yourself and that there was definitely going to be a contest over the prior will (see above), why not go to a real lawyer, revoke the prior will and make another one? On the first few pages, we learn that Seth hated lawyers but liked Jake (by reputation). So get down to the Square in Clanton, have Jake make you a new will, which revokes the earlier one and creates new beneficiaries, and THEN go kill yourself.Finally, there are mysteries here, as to the WHY. Without revealing the who, what, when,... we do find out the answers toward the end. Seth does literally nothing to explain things to anyone before he dies, nor does he leave behind any documents that would explain why he did what he did. This is the same guy who buys a grave plot, arranges things with the undertaker, plans who will sing which hymn at his service and names his pallbearers. But he doesn't give any reason for why he leaves his fortune to his housekeeper. It remains for a third party to provide the explanation. Seth has a very valid reason--why on earth would he take that to the grave, knowing that it may remain a mystery for all time? For a guy we keep hearing about was really sharp and knew what he was doing, I really have my doubts.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "#vectorizer = CountVectorizer()\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#vectorizer.fit(train_x)\n",
    "#train_x_vec=vectorizer.transform(train_x)\n",
    "\n",
    "train_x_vec=vectorizer.fit_transform(train_x) #Does the same thing as above, usually preferred.\n",
    "\n",
    "test_x_vec=vectorizer.transform(test_x)#Not using fit as we dont want to train our test data.\n",
    "\n",
    "print(train_x[0])\n",
    "train_x_vec.toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Linear SVM is : 0.8076923076923077\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_svm=svm.SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(train_x_vec,train_y)\n",
    "\n",
    "predicted_svm = clf_svm.predict(test_x_vec)\n",
    "\n",
    "print('Accuracy of Linear SVM is :' , accuracy_score(test_y,predicted_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree is : 0.6298076923076923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as dt\n",
    "\n",
    "clf_dec = dt()\n",
    "clf_dec.fit(train_x_vec,train_y)\n",
    "predicted_dec = clf_dec.predict(test_x_vec)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy of Decision Tree is :' , accuracy_score(test_y,predicted_dec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gaussian Naive Bayes is : 0.6610576923076923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_nb = GaussianNB()\n",
    "clf_nb.fit(train_x_vec.toarray(),train_y)\n",
    "predicted_nb = clf_nb.predict(test_x_vec.toarray())\n",
    "\n",
    "print('Accuracy of Gaussian Naive Bayes is :' , accuracy_score(test_y,predicted_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression is : 0.8028846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lg\n",
    "clf_log = lg()\n",
    "clf_log.fit(train_x_vec,train_y)\n",
    "predicted_log = clf_log.predict(test_x_vec)\n",
    "\n",
    "print('Accuracy of Logistic Regression is :' , accuracy_score(test_y,predicted_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Linear SVM is : 0.8076923076923077\n",
      "Accuracy of Decision Tree is : 0.6298076923076923\n",
      "Accuracy of Gaussian Naive Bayes is : 0.6610576923076923\n",
      "Accuracy of Logistic Regression is : 0.8028846153846154\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Linear SVM is :', clf_svm.score(test_x_vec,test_y))# Score() function directly predicts as well as calculates the accuracy of the test data.\n",
    "print('Accuracy of Decision Tree is :', clf_dec.score(test_x_vec,test_y))\n",
    "print('Accuracy of Gaussian Naive Bayes is :',clf_nb.score(test_x_vec.toarray(),test_y))\n",
    "print('Accuracy of Logistic Regression is :', clf_log.score(test_x_vec,test_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of Linear SVM is : [0.80582524 0.80952381]\n",
      "F1 score of Decision Tree is : [0.62980769 0.62980769]\n",
      "F1 score of Gaussian Naive Bayes : [0.65693431 0.66508314]\n",
      "F1 score of Logistic Regression is is : [0.80097087 0.8047619 ]\n"
     ]
    }
   ],
   "source": [
    "print('F1 score of Linear SVM is :',f1_score(test_y,predicted_svm,average=None,labels=[Sentiment.Positive,Sentiment.Negative]))\n",
    "print('F1 score of Decision Tree is :',f1_score(test_y,predicted_dec,average=None,labels=[Sentiment.Positive,Sentiment.Negative]))\n",
    "print('F1 score of Gaussian Naive Bayes :',f1_score(test_y,predicted_nb,average=None,labels=[Sentiment.Positive,Sentiment.Negative]))\n",
    "print('F1 score of Logistic Regression is is :',f1_score(test_y,predicted_log,average=None,labels=[Sentiment.Positive,Sentiment.Negative]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the string :Nice concept\n",
      "['POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "#checking_set=['Great book', 'what an amazing book', 'Don\\'t love it']\n",
    "#check_transform= vectorizer.transform(checking_set)\n",
    "checking_input = input('Enter the string :')\n",
    "checking_input=[checking_input]\n",
    "check_transform= vectorizer.transform(checking_input)\n",
    "print(clf_svm.predict(check_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning our Model (with Grid Search)\n",
    "#### Automatically chooses the best parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1, 4, 8, 16, 32], 'kernel': ['linear', 'rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel':['linear','rbf'],'C':[1,4,8,16,32]}\n",
    "svc= svm.SVC(gamma='auto')\n",
    "clf= GridSearchCV(svc,parameters, cv=5)\n",
    "clf.fit(train_x_vec,train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8076923076923077"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_x_vec,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/ridhima gandhi/Desktop/ml/practice_models/sentiment_classifier.pkl','wb') as f:\n",
    "    pickle.dump(clf,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/ridhima gandhi/Desktop/ml/practice_models/sentiment_classifier.pkl','rb') as f:\n",
    "    saved_clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "line = ['Great book']\n",
    "line_transform= vectorizer.transform(line)\n",
    "print(saved_clf.predict(line_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
